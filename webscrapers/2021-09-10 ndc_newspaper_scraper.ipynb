{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1b7926-687b-4ed5-bb68-5235f3c4dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6173b001-29c4-41d1-a369-b4a8d2cda41d",
   "metadata": {},
   "source": [
    "# Functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d534935-8417-4bfa-9e83-99a776c24469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login in\n",
    "USERNAME = \"smussend@umd.edu\"\n",
    "PASSWORD = \"UMDTerps2021\"\n",
    "\n",
    "# Define Computer Paths\n",
    "executable_path = \"C:/Users/nicho/Documents/Code/lynchings_newspapers/webscrapers/scraping_digitized_newspapers/chromedriver.exe\"\n",
    "download_path = r\"C:\\Users\\nicho\\Documents\\Code\\lynchings_newspapers\\webscrapers\\scraping_digitized_newspapers\\downloads\"\n",
    "\n",
    "# URL\n",
    "newspaperdotcomURL = \"https://www.newspapers.com/\"\n",
    "\n",
    "# Define Routes\n",
    "\n",
    "signin_field = '//*[@id=\"signinlink\"]'\n",
    "username_field = '//*[@id=\"username\"]'\n",
    "password_field = '//*[@id=\"password\"]'\n",
    "\n",
    "# Scraping Database Routes\n",
    "\n",
    "column_route = \"parent::node()//following-sibling::div\"\n",
    "# Scraping person result\n",
    "\n",
    "person_result = \"//div[contains(@id, 'search-record-Image-')]\"\n",
    "# Saving Photo & OCR\n",
    "\n",
    "printSaveButton_route = '/html/body/section/div/div[1]/div[1]/div/ul[2]/li[3]/a'\n",
    "saveEntirePage_route = '//*[@id=\"content\"]/div[5]/div[2]/ul[1]/li[1]/a'\n",
    "saveButton_route = '//*[@id=\"content\"]/div[5]/div[2]/ul[2]/li[2]/a'\n",
    "saveJpeg_route = '//*[@id=\"content\"]/div[5]/div[2]/div/ul/li[1]/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444b087b-72ec-41ae-a1ed-cdb7b1ccd571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browser_instance(executable_path, headless = False, download_dir = download_path):\n",
    "    chrome_options =  Options()\n",
    "    if headless:\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    chrome_options.add_argument(\"--disable-notifications\")\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--verbose')\n",
    "    chrome_options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": download_path,\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing_for_trusted_sources_enabled\": False,\n",
    "            \"safebrowsing.enabled\": False})\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    chrome_options.add_argument('--disable-software-rasterizer')\n",
    "    driver = webdriver.Chrome(executable_path=executable_path, options = chrome_options)\n",
    "    return driver    \n",
    "\n",
    "def search_lynching(first_name, last_name, state, lynch_date, days_delta):\n",
    "    # Get dates day_delta before and after lynching\n",
    "    date_before_lynching = datetime.strptime(lynch_date,\"%Y-%m-%d\").date() - timedelta(days=7)\n",
    "    date_after_lynching = datetime.strptime(lynch_date,\"%Y-%m-%d\").date() + timedelta(days=7)\n",
    "    \n",
    "    url = f'https://www.newspapers.com/search/#query={first_name}+{last_name}&p_province=us-{state}&ymd-start={date_before_lynching}&ymd-end={date_after_lynching}'\n",
    "    return url\n",
    "def signIn(driver, url, signin_field, username_field, password_field):  \n",
    "    driver.get(url)\n",
    "    sign_in = driver.find_element_by_xpath(signin_field)\n",
    "    sign_in.click()\n",
    "    email_field = driver.find_element_by_xpath(username_field)\n",
    "    password_field = driver.find_element_by_xpath(password_field)\n",
    "    email_field.send_keys(USERNAME)\n",
    "    password_field.send_keys(PASSWORD + Keys.RETURN)\n",
    "\n",
    "\n",
    "def value_from_url(url):\n",
    "    final_url = url[:-1].rsplit('/', 1)[-1]\n",
    "    return final_url\n",
    "\n",
    "def break_up_url(url):\n",
    "    folder_dict = {}\n",
    "    url = url\n",
    "    for i in range(0,6):\n",
    "        if i == 0:\n",
    "            key = \"day\"\n",
    "            value = url[:-1].rsplit('/', 1)[1]\n",
    "            folder_dict[key] = value\n",
    "            url = url[:-1].rsplit('/', 1)[0]\n",
    "        else:        \n",
    "            if i == 1:\n",
    "                key = \"month\"\n",
    "            if i == 2:\n",
    "                key = \"year\"\n",
    "            if i == 3:\n",
    "                key = \"newspaper\"\n",
    "            if i == 4:\n",
    "                key = \"city\"\n",
    "            if i ==5:\n",
    "                key = \"state\"\n",
    "            value = url.rsplit('/', 1)[1]\n",
    "            folder_dict[key] = value\n",
    "            url = url[:-1].rsplit('/', 1)[0]\n",
    "    return folder_dict\n",
    "\n",
    "def write_json_data(data_out, database_name, file_path):\n",
    "        #writing data to json\n",
    "        data_out = data_out\n",
    "        database_name = database_name\n",
    "        file = f'{file_path}/{database_name}'\n",
    "        with open(file, 'w') as outfile:\n",
    "            json.dump(data_out, outfile)\n",
    "            \n",
    "def open_json_data(file_path):    \n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "            \n",
    "def get_element(driver,route,word = \"NA\"):   \n",
    "    if word != \"NA\":\n",
    "        complete_route = f'//*[contains(text(), \"{word}\")]/' + route \n",
    "       \n",
    "    else:\n",
    "        complete_route = route\n",
    "        \n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, complete_route)))\n",
    "    \n",
    "    return element\n",
    "\n",
    "def get_list_column_entries(driver,url, word, column_route, full = True, duplicate_links = False):\n",
    "    if url != \"NA\":\n",
    "        driver.get(url)\n",
    "    element_list = get_element(driver,column_route, word = word )\n",
    "    element_list_url = element_list.find_elements_by_tag_name(\"a\")\n",
    "    list_elements = []\n",
    "    counter = 1\n",
    "    for element in element_list_url:\n",
    "        if duplicate_links:\n",
    "            if counter % 2 == 1: #there are two of same links, only need to grab one of them\n",
    "                if full:\n",
    "                    list_elements.append(element.get_attribute(\"href\"))\n",
    "                else:\n",
    "                    list_elements.append(value_from_url(element.get_attribute(\"href\")))\n",
    "            counter = counter +1\n",
    "        else:            \n",
    "            if full:\n",
    "                list_elements.append(element.get_attribute(\"href\"))\n",
    "            else:\n",
    "                list_elements.append(value_from_url(element.get_attribute(\"href\")))\n",
    "    return(list_elements)\n",
    "\n",
    "def get_person_results(results):\n",
    "    newspaper_info = []\n",
    "    for chunk in results:\n",
    "        url = chunk.find_element_by_tag_name('a').get_attribute(\"href\")\n",
    "        newspaper_title = chunk.find_element_by_tag_name('h2').text\n",
    "        other_information = chunk.find_elements_by_tag_name(\"p\")    \n",
    "        page_location = other_information[0].text\n",
    "        city_state = other_information[1].text\n",
    "        date = other_information[2].text\n",
    "        #num_matches = other_information[3].text\n",
    "        match = {\"url\": url, \"newspaper_title\": newspaper_title, \"page_location\": page_location, \"city_state\":city_state, \"date\": date}\n",
    "        newspaper_info.append(match)\n",
    "    return newspaper_info\n",
    "\n",
    "def get_ocr_text(newspaper_urls):\n",
    "    \"\"\"\n",
    "    input: a list of newspaper urls that link to individual photo pages\n",
    "    action: changes the photo url to a ocr url\n",
    "    output: saves the OCR results from newspaper.com for each photo given\n",
    "    \"\"\"\n",
    "    result_ocr = []\n",
    "    for newspaper_url in newspaper_urls:        \n",
    "        ocr_string = \"https://www.newspapers.com/newspage/\"\n",
    "        ocr_url = ocr_string + newspaper_url[33:]\n",
    "        print(ocr_url)\n",
    "        driver.get(ocr_url)\n",
    "        ocr_text = driver.find_element_by_class_name(\"ocrtext\").text\n",
    "        match_ocr = {\"url\": newspaper_url, \"ocr_text\": ocr_text}\n",
    "        result_ocr.append(match_ocr)\n",
    "    return result_ocr\n",
    "\n",
    "def save_photo(driver, url, printSaveButton_route = printSaveButton_route, saveEntirePage_route= saveEntirePage_route, saveButton_route= saveButton_route, saveJpeg_route = saveJpeg_route):\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    #Initial Save button\n",
    "    print_save_button = get_element(driver, printSaveButton_route)        \n",
    "    print_save_button.click()\n",
    "    print(\"clicked\")\n",
    "\n",
    "    #Save Entire page\n",
    "    entire_page_button = get_element(driver, saveEntirePage_route )\n",
    "    entire_page_button.click()\n",
    "\n",
    "    #Save page\n",
    "    save_button = get_element(driver,saveButton_route)   \n",
    "    save_button.click()\n",
    "\n",
    "    #Save Jpeg\n",
    "    save_jpeg_button = get_element(driver, saveJpeg_route)\n",
    "    save_jpeg_button.click()\n",
    "    time.sleep(7)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c27f5d-e561-4cc1-a00d-f21abb101c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\Documents\\Code\\lynchings_newspapers\\webscrapers\\scraping_digitized_newspapers\\downloads\n",
      "C:\\Users\\nicho\\Documents\\Code\\lynchings_newspapers\\webscrapers\\scraping_digitized_newspapers\\downloads\\test\n"
     ]
    }
   ],
   "source": [
    "directory = \"test\"\n",
    "path = os.path.join(download_path, directory)\n",
    "\n",
    "print(download_path)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c49a6d7-c951-41e4-8ff7-2cbb21723213",
   "metadata": {},
   "source": [
    "# Scratch Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b8586-58ae-4a00-bbf2-51b6d86b3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = browser_instance(executable_path)\n",
    "signIn(driver, url, signin_field, username_field, password_field)\n",
    "time.sleep(2)\n",
    "newspaper= \"queen-city-times_18783\"\n",
    "year = \"1906\"\n",
    "city = \"agra\"\n",
    "state = \"oklahoma\"\n",
    "lynch_month = 10\n",
    "url_year = f\"https://www.newspapers.com/browse/us/{state}/{city}/{newspaper}/{year}/\"\n",
    "\n",
    "months = get_list_column_entries(driver,url_year,\"MONTH\", column_route, full = False)\n",
    "\n",
    "\n",
    "chosen_months = []\n",
    "for month in months:\n",
    "    int_month = int(month)\n",
    "    if int_month == lynch_month - 1 or int_month == lynch_month+1:\n",
    "        chosen_months.append(month)\n",
    "\n",
    "urls_with_month = []        \n",
    "for month in chosen_months:  \n",
    "    url =  f\"https://www.newspapers.com/browse/us/{state}/{city}/{newspaper}/{year}/{month}/\"\n",
    "    urls_with_month.append(url)\n",
    "\n",
    "list_dates_url = []\n",
    "for url in urls_with_month:\n",
    "    temp = get_list_column_entries(driver, url, \"DATE\", column_route,  True, False)\n",
    "    [list_dates_url.append(x) for x in temp]\n",
    "\n",
    "\n",
    "for url in list_dates_url:\n",
    "    list_pages_url = get_list_column_entries(driver, url, \"PAGE\", column_route,  True, False) \n",
    "    url_dict = break_up_url(url)\n",
    "    directory = f'{url_dict[\"state\"]}_{url_dict[\"city\"]}_{url_dict[\"newspaper\"]}_{url_dict[\"year\"]}_{url_dict[\"month\"]}'\n",
    "    path = os.path.join(download_path, directory)\n",
    "    print(path)\n",
    "    print(type(path))\n",
    "    os.mkdir(path)\n",
    "    driver.quit()    \n",
    "    for page in list_pages_url:        \n",
    "        driver2 = browser_instance(executable_path, download_dir = f'{download_path}\\{directory}' )        \n",
    "        signIn(driver2, url, signin_field, username_field, password_field)\n",
    "        time.sleep(2)\n",
    "        save_photo(driver2, page)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "14e78031-2e42-457a-95d7-11c59aac9abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\nicho\\\\Documents\\\\Code\\\\lynchings_newspapers\\\\webscrapers\\\\scraping_digitized_newspapers\\\\downloads'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{download_path}'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "277be4f6-f6a7-4918-8a77-df2f51aed353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7db14aa8-619c-462e-a051-937b996329ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "folder_dict = {}\n",
    "url = \"https://www.newspapers.com/browse/us/oklahoma/agra/queen-city-times_18783/1906/09/20/\"\n",
    "for i in range(0,6):\n",
    "    if i == 0:\n",
    "        key = \"day\"\n",
    "        value = url[:-1].rsplit('/', 1)[1]\n",
    "        folder_dict[key] = value\n",
    "        url = url[:-1].rsplit('/', 1)[0]\n",
    "    else:        \n",
    "        if i == 1:\n",
    "            key = \"month\"\n",
    "        if i == 2:\n",
    "            key = \"year\"\n",
    "        if i == 3:\n",
    "            key = \"newspaper\"\n",
    "        if i == 4:\n",
    "            key = \"city\"\n",
    "        if i ==5:\n",
    "            key = \"state\"\n",
    "        value = url.rsplit('/', 1)[1]\n",
    "        folder_dict[key] = value\n",
    "        url = url[:-1].rsplit('/', 1)[0]\n",
    "return folder_dict\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0c78fcd3-39e0-4a5f-97eb-70c929bb75f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.newspapers.com/browse/us/oklahoma/agra/queen-city-times_18783/1906/09/20\"\n",
    "print(url.rsplit('/', 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7226e718-86cc-49ec-be05-3f50fa584660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_json = open_json_data(\"newspaperdotcom_newjersey_ohio.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "400fa6ad-d31d-454e-9635-100ab5ee78a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allentown-messenger_9256 --> ['1903', '1904', '1905', '1906', '1907', '1908', '1909', '1910', '1911', '1912', '1913', '1914', '1915', '1916', '1917', '1918', '1919', '1920', '1921', '1922', '1923', '1924', '1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939', '1940', '1941', '1942', '1943', '1944', '1945', '1946', '1947', '1948', '1949', '1950', '1951', '1952', '1953', '1954', '1955', '1956', '1957', '1958', '1959', '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968', '1969', '1970', '1971']\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "states_list = [\"new-jersey\"]\n",
    "cities_list = [\"allentown\"]\n",
    "years_list = [\"1956\"]\n",
    "for state_entry in df_json:    \n",
    "    if state_entry[\"state\"] in states_list:\n",
    "        city_entry = state_entry[\"city\"]        \n",
    "        for city, newspapers in city_entry.items(): \n",
    "            if city in cities_list:\n",
    "                for newspaper, years in newspapers.items():\n",
    "                    #print(newspaper, \"-->\", years)\n",
    "                    if any(item in years for item in years_list):\n",
    "                        pass\n",
    "                        #print(\"======\")\n",
    "                        print(newspaper, \"-->\", years)\n",
    "                    \n",
    "        \n",
    "       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a890be3-8a0b-4717-8a80-3e420f098093",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-14e19b2a29fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_json\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"new-jersey\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "test = {key:value for key,value in df_json.items() if key in [\"new-jersey]\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0cf870-5dac-4aea-92a9-c34b34c7ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72cafcd9-8e93-4d2d-9f69-da1671368043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09', '11']\n"
     ]
    }
   ],
   "source": [
    "lynch_month = 10\n",
    "chosen_months = []\n",
    "for month in months:\n",
    "    int_month = int(month)\n",
    "    if int_month == lynch_month - 1 or int_month == lynch_month+1:\n",
    "        chosen_months.append(month)\n",
    "print(chosen_months)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78828b-1c98-4d6b-9c9c-cd8868c05f90",
   "metadata": {},
   "source": [
    "# Person Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188f6bf-74c2-454a-8aaa-3c0f77048f10",
   "metadata": {},
   "source": [
    "## Sign in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d35f4a4-bcc9-4d2d-9fea-6c0698c2a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = browser_instance(executable_path, False)\n",
    "signIn(driver, newspaperdotcomURL, signin_field, username_field, password_field)\n",
    "time.sleep(3)\n",
    "driver.get(search_lynching(\"luther\", \"holbert\", \"ms\",\"1904-02-01\", 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c6cf3-06d5-4568-b7d1-175cc333649d",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aaf452-1109-4871-990a-4558d3707eeb",
   "metadata": {},
   "source": [
    "### Person Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320fceea-93c8-4bff-893a-3e4c05c61dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = driver.find_elements_by_xpath(person_result)\n",
    "newspaper_info = get_person_results(results)\n",
    "df_newspaper_info = pd.DataFrame(newspaper_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf2846-5c04-4e52-8d93-fe8b857be807",
   "metadata": {},
   "source": [
    "### Save Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04e1bf28-07c6-4067-a066-1f68fabbff0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n",
      "clicked\n",
      "clicked\n",
      "clicked\n",
      "clicked\n",
      "clicked\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-068fda4e6795>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnewspaper\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnewspaper_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewspaper\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0msave_photo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-31eb0df0b74c>\u001b[0m in \u001b[0;36msave_photo\u001b[1;34m(driver, url, printSaveButton_route, saveEntirePage_route, saveButton_route, saveJpeg_route)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0msave_jpeg_button\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveJpeg_route\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[0msave_jpeg_button\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for newspaper in newspaper_info:\n",
    "    url = newspaper[\"url\"]    \n",
    "    save_photo(driver, url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd50f6-32ed-4cce-8070-0721eeb8e92c",
   "metadata": {},
   "source": [
    "### SAVE OCR Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50323bff-ef05-4079-ac0e-af4407826bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper_urls = []\n",
    "for newspaper in newspaper_info:\n",
    "    newspaper_urls.append(newspaper[\"url\"])\n",
    "\n",
    "result_ocr = get_ocr_text(newspaper_urls)\n",
    "df_result_ocr = pd.DataFrame(result_ocr)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd99e1f-269a-4ff4-b127-9b0d0b7cad9f",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ac59c-21e7-44d4-aba4-e882639846f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newspaper_result = pd.merge(df_result_ocr, df_newspaper_info)\n",
    "df_newspaper_result.to_csv(\"df_newspaper_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a9ffe-4f45-45ff-876e-a755f15b87d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
